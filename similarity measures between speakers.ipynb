{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRECUENCIA FUNDAMENTAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " La voz puede caracterizarse por varios parámetros. El <b>TONO</b> de la voz es una de las características principales, pero en el campo de las tecnologías acústicas, el nombre correcto de este parámetro es la <b>frecuencia fundamental</b>.\n",
    " \n",
    " La frecuencia fundamental está directamente <b>relacionada</b> con lo que llamamos <b>entonación</b>. Y la entonación, por ejemplo, está asociada con características expresivas de la voz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F0 = La frecuencia fundamental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frecuencia de vibración de los ligamentos al pronunciar sonidos sonoros.\n",
    "En sonidos sordos como por ejemplo: susurrar o silbar, los ligamentos no vibran, por lo tanto esta característica no es relevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variabilidad de la frecuencia fundamental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede variar por genero, discurso emocional, etc.\n",
    "\n",
    "- Voces masculinas, el menor promedio esta entre 70–200 Hz\n",
    "- Voces femeninas, pueden alcanzar los 400Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campos de aplicación del F0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Emotion Recognition\n",
    "2. Sex determination (male/female voices)\n",
    "3. Speaker deterioration, or splitting the speech into phrases\n",
    "4. In healthcare, detection of the pathological characteristics of the voice.\n",
    "\n",
    "<b>Nota: </b> Utilizando los parámetros acústicos de Jitter y Shimmer): F0 podría utilizarse para la detección de signos de la enfermedad de <b>Parkinson</b>. Estos parametros también puede utilizarse para el reconocimiento de emociones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ilusión auditiva de Laurel y Yanny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/YOUTUBE_VIDEO_ID_HERE/0.jpg)](https://www.youtube.com/watch?v=yDiXQl7grPQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La percepción de F0, que está influenciada por muchos factores: la edad del oyente, el grado de cansancio del oyente, la calidad del sistema de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F0 métodos de estimación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se dividen en tres categorías\n",
    "\n",
    "1. Basados en dinámica temporal de la señal o dominio de tiempo (<b>Time-domain</b>)\n",
    "2. Basados en la estructura de la frecuencia o dominio de la frecuencia (<b>Frequency-domain</b>)\n",
    "3. Métodos híbridos (<b>Hybrid</b>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapas de los métodos de estimación\n",
    "1. Preprocesamiento (filtrado de la señal, división en ventanas)\n",
    "2. Buscando posibles valores para F0 (candidatos)\n",
    "3. Seguimiento: la elección de la trayectoria F0 más probable (lo cual es importante ya que en cada momento tenemos varios candidatos compitiendo simultáneamente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time-domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de aplicar los métodos del dominio del tiempo, la señal se filtra para dejar sólo las frecuencias bajas. \n",
    "\n",
    "##### Consideraciones\n",
    "\n",
    "- Se establecen los umbrales: frecuencias mínimas y máximas, por ejemplo, de 75 a 500 Hz. \n",
    "- La estimación de F0 sólo se realiza para el discurso armónico.\n",
    "- Las secciones con pausas o manchas de ruido pueden alterar los neighboring frames y conducir a errores cuando se aplica la interpolación o el suavizado. \n",
    "- La longitud del frame se elige de manera que comprenda al menos tres intervalos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelations\n",
    "\n",
    "Principal algoritmo,\n",
    "\n",
    "- Se calcula la función de autocorrelación y luego se define su primer máximo que reflejará la componente de frecuencia más destacada de la señal.\n",
    "\n",
    "El problema de este algoritmo es que el primer máximo no siempre puede corresponder a la frecuencia deseada. En condiciones casi perfectas en grabaciones de alta calidad, el algoritmo es propenso a errores debido a la compleja estructura de la señal. En las condiciones cercanas a la realidad, el número de errores aumenta drásticamente. Además, en las grabaciones de baja calidad inicial y ruidosas se puede presentar la ausencia del pico deseado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de los errores es ampliamente utilizado en muchos algoritmos, incluyendo el YIN. El nombre en sí mismo se refiere a la idea del equilibrio entre la conveniencia y la inexactitud de la autocorrelación: \"El nombre YIN de ''yin'' y ''yang'' de la filosofía oriental alude a la interacción entre la autocorrelación y la cancelación que implica\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The creators of YIN tried to fix the problem. The first thing they changed was the use of Cumulative Mean Normalized Difference function that was supposed to lower the sensitivity of the signal to the amplitude modulations and make the peaks more apparent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/806/1*13edEhKas4F3VyuUu4a7jg.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YIN tries to avoid the mistakes that come up when the length of the window function is not exactly divisible into the fluctuation period. For that matter, parabolic interpolation to approximate the minimum is applied. At the last step of the audio signal processing Best Local Estimate function is used to avoid rapid fluctuation of the values. (Whether it is good or bad — it is hard to tell.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Frequency-domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando hablamos del dominio de la frecuencia, el aspecto más prominente parece ser la estructura armónica de la señal. En otras palabras, los picos espectrales en la frecuencia que son divisible en F0. Se puede convertir este patrón periódico en un pico obvio con la ayuda del análisis cepstrum. Cepstrum es una transformada de Fourier (FFT) del logaritmo del espectro de potencia estimado. El pico del cepstrum corresponde a la componente más periódica del espectro.\n",
    "https://pdfs.semanticscholar.org/5dc0/f86273c58d4d05b01882b197facf58b1ab1a.pdf\n",
    "\n",
    "A History of Cepstrum Analysis and its Application to Mechanical Problems\n",
    "https://surveillance7.sciencesconf.org/conference/surveillance7/01_a_history_of_cepstrum_analysis_and_its_application_to_mechanical_problems.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAAPT\n",
    "Algorithm of Pitch Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se clasifica como híbrido ya que utiliza datos temporales y de frecuencia. [Mas info](http://www.ws.binghamton.edu/zahorian/pdf/icslp2006_pitch_v16.pdf)\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocesamiento: los valores de la señal inicial se cuadran para obtener una segunda versión de la señal\n",
    "2. Se amplificar y restaurar los picos \"atascados\" de autocorrelación, usando la función de diferencia normalizada media acumulada de YIN.\n",
    "3. Ambas versiones de la señal(version original y la generada en el paso 1) se filtran, generalmente en el espectro de 50–1500 Hz, o 50–900 Hz.\n",
    "4. Basado en el espectro de la señal transformada, se calcula la trayectoria básica de F0. Los candidatos a F0 se determinan con la función de Correlación de Armónicos Espectrales (SHC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/812/1*dqn-LRCthMh9OTNOOc04XA.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n",
    "     \n",
    "      where S(t,f) is a magnitude spectrum of the frame t and frequency f, WL is the length of a window in Hz, NH is the number of harmonics (the authors of the article suggest using the first three harmonics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. La definición de los cuadros de voz se hace en base al espectro de potencia también. Luego buscamos la trayectoria más óptima, teniendo en cuenta la posibilidad de doblar el tono o reducirlo a la mitad.\n",
    "\n",
    "6. Tanto para las señales iniciales como para las transformadas, los candidatos a F0 se determinan con Correlación Cruzada Normalizada (NCCF), en lugar de autocorrelación. usando la siguiente formula:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1218/1*YRkNvYJoWcrapF6swn4KqA.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Evaluar a todos los posibles candidatos y calcular su peso. El peso de los candidatos depende no sólo del pico de amplitud de la FNCA, sino también de su proximidad a la trayectoria F0 que fue determinada por el espectro. Por lo tanto, el dominio de la frecuencia se considera bastante contundente todavía y estable.\n",
    "\n",
    "9. Para todos los pares de candidatos restantes se calcula la matriz del Costo de Transición - el costo de la transición que permite encontrar la mejor trayectoria posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Usamos las librerias: <b>aubio</b> y <b>AMFM_descomposition</b> usadas para hacer pitch-tracking.\n",
    " \n",
    " - AMFM_decomposition usa el algoritmo YAAPT\n",
    " - Aubio usa el algoritmo YIN por defecto\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install amfm_decompy\n",
    "#! pip install aubio\n",
    "#! pip install source\n",
    "#! pip install pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import amfm_decompy.basic_tools as basic\n",
    "import amfm_decompy.pYAAPT as pYAAPT\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import aubio\n",
    "#import sys from aubio\n",
    "import source, pitch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load audio\n",
    "signal = basic.SignalObj('/home/eva/Documents/papers/habr/media/audio.wav')\n",
    "filename = '/home/eva/Documents/papers/habr/media/audio.wav'\n",
    "# YAAPT pitches \n",
    "pitchY = pYAAPT.yaapt(signal, frame_length=40, tda_frame_length=40, f0_min=75, f0_max=600)\n",
    "# YIN pitches\n",
    "downsample = 1\n",
    "samplerate = 0\n",
    "win_s = 1764 // downsample # fft size\n",
    "hop_s = 441 // downsample # hop size\n",
    "s = source(filename, samplerate, hop_s)\n",
    "samplerate = s.samplerate\n",
    "tolerance = 0.8\n",
    "pitch_o = pitch(\"yin\", win_s, hop_s, samplerate) pitch_o.set_unit(\"midi\")\n",
    "pitch_o.set_tolerance(tolerance)\n",
    "pitchesYIN = []\n",
    "confidences = [] \n",
    "total_frames = 0\n",
    "while True:\n",
    "     samples, read = s()\n",
    "     pitch = pitch_o(samples)[0]\n",
    "     pitch = int(round(pitch))\n",
    "     confidence = pitch_o.get_confidence()\n",
    "     pitchesYIN += [pitch]\n",
    "     confidences += [confidence]\n",
    "     total_frames += read\n",
    "     if read < hop_s:\n",
    "         break          \n",
    "# load PRAAT pitches\n",
    "praat = np.genfromtxt('/home/eva/Documents/papers/habr/PraatPitch.txt', filling_values=0)\n",
    "praat = praat[:,1]\n",
    "# plot\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(3, 1, sharex=True, sharey=True, figsize=(12, 8))\n",
    "ax1.plot(np.asarray(pitchesYIN), label='YIN', color='green')\n",
    "ax1.legend(loc=\"upper right\")\n",
    "ax2.plot(pitchY.samp_values, label='YAAPT', color='blue')\n",
    "ax2.legend(loc=\"upper right\")\n",
    "ax3.plot(praat, label='Praat', color='red')\n",
    "ax3.legend(loc=\"upper right\") plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog guía:  https://medium.com/@neurodatalab/pitch-tracking-or-how-to-estimate-the-fundamental-frequency-in-speech-on-the-examples-of-praat-fe0ca50f61fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
